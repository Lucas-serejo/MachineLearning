# Simula√ß√£o de Aprendizado de M√°quina Federado com Python

## üéØ Objetivo

Simular o processo de aprendizado federado utilizando m√∫ltiplos conjuntos de dados locais e um servidor central para agrega√ß√£o dos modelos. A proposta visa compreender os conceitos de privacidade, descentraliza√ß√£o e atualiza√ß√£o global do modelo.

---

## üë• Participantes

| Nome Completo         | Matr√≠cula     |
|-----------------------|---------------|
|Lucas Jos√© Silva Serejo|202202714356   |
|Beatriz Turi Pinto de Araujo|202203795211|
|Pedro Henrique Rossetto Costa|202108581259|
|Lucas Fernandes Mosqueira|202203369016|

---

## üìÅ Dataset Utilizado

**Fashion-MNIST**: Dataset de imagens de roupas (28x28 pixels, tons de cinza).  
- Total de amostras: 70.000  
- Conjunto de treino: 60.000  
- Conjunto de teste: 10.000  
- Classes: 10 tipos de roupas  
- Tarefa: Classifica√ß√£o multiclasse  

---

## üîÄ Divis√£o dos Dados

- O conjunto de treino foi dividido igualmente entre **5 clientes simulados**, com 12.000 amostras cada.
- A divis√£o foi feita de forma **balanceada e aleat√≥ria** (IID).
- Cada cliente treinou seu modelo **localmente**, sem acesso aos dados dos demais.

---

## üß† Modelo Utilizado

- Tipo: **MLP (Multi-Layer Perceptron)**
- Estrutura:
  - Camada densa (128 neur√¥nios, ReLU)
  - Camada de sa√≠da (10 neur√¥nios, Softmax)
- Otimizador: **Adam**
- Perda: `sparse_categorical_crossentropy`

---

## üõ†Ô∏è Treinamento Local

Cada cliente realizou seu pr√≥prio treinamento local com:
- **1 √©poca por rodada federada**
- **Batch size:** 32
- **Inicializa√ß√£o com pesos do modelo global**
- **Retorno dos pesos locais ao servidor**

---

## üîó Agrega√ß√£o no Servidor (FedAvg)

A agrega√ß√£o foi realizada via **m√©dia simples (FedAvg)** dos pesos recebidos de todos os clientes.  
Ap√≥s a agrega√ß√£o, o modelo global foi atualizado e redistribu√≠do para os clientes na pr√≥xima rodada.

---

## üîÅ Rodadas Federadas

- N√∫mero de rodadas: **5**
- A cada rodada:
  1. Clientes recebem pesos do modelo global
  2. Treinam localmente
  3. Enviam pesos atualizados
  4. Servidor agrega e atualiza o modelo

---

## üß™ Avalia√ß√£o e Resultados

### üìà Modelo Federado
- **Acur√°cia final ap√≥s 5 rodadas:** `85.90%`  
- **Perda final:** `0.3962`

### üèÅ Modelo Centralizado
- **Acur√°cia:** `86.99%`  
- **Perda:** `0.3709`

### üìä Comparativo

| Modelo               | Acur√°cia | Perda |
|----------------------|----------|--------|
| Federado (5 rounds)  | 85.90%  | 0.3962 |
| Centralizado         | 86.99%   | 0.3709 |

> _Observa√ß√£o: o modelo centralizado apresentou melhor desempenho, como esperado, pois treina com o conjunto completo e homog√™neo. Ainda assim, o modelo federado teve desempenho competitivo sem precisar centralizar os dados._

---

## üìå Conclus√µes

- O aprendizado federado se mostrou eficaz em alcan√ßar boa acur√°cia sem centralizar os dados.
- O processo pode ser expandido com dados **n√£o-IID**, mais clientes e arquiteturas mais complexas.
- Em cen√°rios reais, a privacidade e a comunica√ß√£o s√£o t√£o importantes quanto a performance do modelo.

"""

# Salvar o relat√≥rio em arquivo .md
caminho_arquivo = "/mnt/data/relatorio_federated_learning.md"
with open(caminho_arquivo, "w", encoding="utf-8") as f:
    f.write(relatorio_md)

caminho_arquivo
